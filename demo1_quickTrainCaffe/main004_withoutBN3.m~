%% quick setup
clear
% close all
clc;

run(fullfile('../../CompactBilinearPool/MatConvNet/vlfeat','toolbox','vl_setup'));
% run(fullfile('../vlfeat','toolbox','vl_setup'));
run(fullfile('../matconvnetToolbox', 'matlab', 'vl_setupnn'));
addpath('../');
addpath(genpath('../froBiCls'));
addpath(genpath('../addLayerFunc'));
addpath(genpath('../get_activations'));
addpath(genpath('../get_batch'));
addpath(genpath('../linear_classifier'));
addpath(genpath('../prepare_dataset'));
addpath(genpath('../layers'));
addpath(genpath(fullfile('../matconvnetToolbox','examples')));

addpath(genpath('../../exportFig'));
%% configuration
% dataset: 'CUB' (bird), 'MIT' (indoor scene), 'FMD' (fclikr material), 
% 'DTD' (describable texture), 'aircraft' (ox), 'cars' (stanford)
dataset = 'CUB';

% network: VGG_M, VGG_16, VGG_19, resnet-152, resnet-50, resnet-101
netbasemodelName = 'VGG_16';

gpuId = 3;
gpuDevice(gpuId);

learningRate = [ones(1, 24)*0.01, ones(1, 100)*0.001, ones(1, 60)*0.0001];
% weightDecay: usually use the default value
weightDecay=0.000005;
%% prepare data
% dataset: 'CUB', 'MIT', 'DTD', 'aircrafts', 'cars'
if strcmp(dataset, 'CUB')
    num_classes = 200;
    dataDir = './data/cub';
%     imdbFile = fullfile('imdbFolder', dataset, [lower(dataset) '-seed-01'], 'imdb-seed-2_flipAug.mat');
    imdbFile = fullfile('../imdbFolder', dataset, [lower(dataset) '-seed-01'], 'imdb-seed-1.mat');
    if ~exist(imdbFile, 'file')        
        imdb = cub_get_database(dataDir);        
        imdbDir=fileparts(imdbFile);
        if ~isdir(imdbDir)
            mkdir(imdbDir);
        end
        save(imdbFile, '-struct', 'imdb') ;
    end
elseif strcmp(dataset, 'DTD')
    num_classes = 47;
    dataDir = '../data/dtd';
    imdbFile = fullfile('../imdbFolder', dataset, [lower(dataset) '-seed-01'], 'imdb-seed-1.mat');
    if ~exist(imdbFile, 'file')        
        imdb = dtd_get_database(dataDir);
        
        imdbDir = fileparts(imdbFile);
        if ~isdir(imdbDir)
            mkdir(imdbDir);
        end
        save(imdbFile, '-struct', 'imdb') ;
    end
elseif strcmp(dataset, 'aircraft')
    dataDir = '../data/aircraft';
    imdbFile = fullfile('../imdbFolder', dataset, [lower(dataset) '-seed-01'], 'imdb-seed-1.mat');    
    num_classes = 100;
    if ~exist(imdbFile, 'file')        
        imdb = aircraft_get_database(dataDir, 'variant'); % family (70), manufacturer (30), variant (100)
        
        imdbDir = fileparts(imdbFile);
        if ~isdir(imdbDir)
            mkdir(imdbDir);
        end
        save(imdbFile, '-struct', 'imdb') ;
    end
elseif strcmp(dataset, 'cars')
    dataDir = '../data/cars';
    imdbFile = fullfile('../imdbFolder', dataset, [lower(dataset) '-seed-01'], 'imdb-seed-1.mat');    
    num_classes = 196;
    if ~exist(imdbFile, 'file')        
        imdb = cars_get_database(dataDir, 'variant'); % family (70), manufacturer (30), variant (100)
        
        imdbDir = fileparts(imdbFile);
        if ~isdir(imdbDir)
            mkdir(imdbDir);
        end
        save(imdbFile, '-struct', 'imdb') ;
    end
end
%% read pre-trained model and initialize network
%% read pre-trained model and initialize network
netbasemodel = load('/home/skong2/data/BirdProject/matconvnetBilinear/imdbFolder/CUB/exp/CUB_VGG_16_SVM_bilinear_448_final5FullBCNN/CUB_VGG_16_SVM_bilinear_448_net-epoch-13.mat');
netbasemodel = netbasemodel.net;
netbasemodel = vl_simplenn_tidy(netbasemodel) ;
vl_simplenn_display(netbasemodel);
endLayer = 30;
%% modify the pre-trained model to fit the current size/problem/dataset/architecture, excluding the final layer
batchSize = 16; % 32 for 224x224 image inpute, 8 for 448x448 input image size 
mopts.poolType='bilinear';

% only for pretrain multilayer perception
mopts.isPretrainFCs = false;
mopts.fc1Num = -1;
mopts.fc2Num = -1;
mopts.fcInputDim = 512*512;

% some usually fixed params
mopts.ftConvOnly = false;
mopts.use448 = true;
% mopts.use448 = false;
if mopts.use448
    inputImgSize = 448;
else
    inputImgSize = 224;
end
mopts.classifyType='SVM'; % or SVM or LR
mopts.initMethod='pretrain'; % or 'pretrain' 'random' 'FroBiSVM' 'symmetricFullSVM'

% some parameters should be tuned
opts.train.batchSize = batchSize;
opts.train.learningRate = learningRate;
opts.train.weightDecay = weightDecay;
opts.train.momentum = 0.9 ;

% set the batchSize of initialization
mopts.batchSize = opts.train.batchSize;

% fancy PCA
fancyPCA = load('./fancyPCA.mat');
netbasemodel.meta.normalization.rgbVariance = fancyPCA.P* diag(0.1*fancyPCA.d(:));
netbasemodel.meta.normalization.imageSize = [inputImgSize, inputImgSize, 3, netbasemodel.meta.normalization.imageSize(end)];

netbasemodel.layers = netbasemodel.layers(1:endLayer);

% learnable power normalization layer with fixed learning rate
nDim = 512;
ep = 0.1;
lr_p = 0;
pVec = ones(nDim, 1)*0.5;
layer = struct('type', 'custom',...
    'forward',  @learnablePowerNormLayer4biCls_forward, ...
    'backward', @learnablePowerNormLayer4biCls_backward, ...
    'name', 'learnablePowerNormLayer4biCls',...
    'ep', ep, ...    
    'learningRate', lr_p, ...
    'weights', {{pVec}},...
    'weightDecay', 0, ...
    'scaleFactor', 10000, ...
    'precious', 1); 
netbasemodel.layers = horzcat(netbasemodel.layers, layer) ;
%% co-decomposition
rDimBiCls = 20;
nclasses = num_classes;
m = 100; % reduced dimension
rDimBiClsNew = 8;
orgDim = 512;

Pparam = load('car_VGG16');
P = Pparam.U(:,1:m);
P = reshape(P,[1,1,size(P,1),size(P,2)]);
initParam = {{single(P), zeros(size(P,4),1,'single')}};
netbasemodel.layers{end+1} = struct('type', 'conv', ...
    'name', 'dimRedLayer', ...
    'weights', initParam, ...
    'stride', 1, ...
    'pad', 0, ...
    'learningRate', [0 0],...
    'weightDecay', [0 0], ...
    'precious', 1);

outputSize = orgDim*orgDim;
%% add the layer to the network
% init_weight('xavierimproved', 1, 1, nfeature, nclass, 'single')
learnW = [0.01 0.02]; % [0.001 0.002]
lambda = 0.0001;

% 'xavierimproved' -- not sure if this works better, as our model is different from linear convolution operation
sc = sqrt(2/rDimBiClsNew) ;
bisvmU = randn(m, num_classes*rDimBiClsNew, 'single')*sc ;
% gaussian rand init
% bisvmU = single(randn(m,num_classes*rDimBiClsNew)*0.01);

initFCparam = {{single(bisvmU), zeros(1,num_classes, 'single')}};
netbasemodel = addBisvm_posneg_UUregLayer(netbasemodel, mopts.classifyType,  initFCparam, rDimBiClsNew, num_classes, learnW, lambda);

vl_simplenn_display(netbasemodel);
netInfo = vl_simplenn_display(netbasemodel);
%% insert batch normalization layer - between conv and relu
% netbasemodel = insertBnorm(netbasemodel, 25) ;
% netbasemodel = insertBnorm(netbasemodel, 28) ;
% netbasemodel = insertBnorm(netbasemodel, 31) ;
% vl_simplenn_display(netbasemodel);
%% train network
opts.imdbPath = fullfile('../imdbFolder', dataset, [lower(dataset) '-seed-01/imdb-seed-1.mat']);

opts.train.expDir = fullfile('../imdbFolder', dataset, 'exp', [dataset, '_', netbasemodelName, '_', mopts.classifyType, ...
    '_', mopts.poolType, '_', int2str(inputImgSize), '_main001_woBN_v2']);

if ~isdir(opts.train.expDir)
    mkdir(opts.train.expDir);
end
opts.train.numSubBatches = 1 ;
opts.train.continue = true ;
opts.train.gpus = gpuId ;
%gpuDevice(opts.train.gpus); % don't want clear the memory
opts.train.prefetch = true ;
opts.train.sync = false ; % for speed
opts.train.cudnn = true ; % for speed
opts.train.numEpochs = numel(opts.train.learningRate) ;

imdb = load(opts.imdbPath) ;

% in case some dataset only has val/test
opts.train.val = find(imdb.images.set==3);
% opts.train.val = union(find(imdb.images.set==2), find(imdb.images.set==3));
opts.train.train = [];

bopts = netbasemodel.meta.normalization;
bopts.numThreads = 12;
fn = getBatchWrapperModeAware_car(bopts) ;
opts.train.backPropDepth = inf; % could limit the backprop

prefixStr = [dataset, '_', netbasemodelName, '_', mopts.classifyType, '_', mopts.poolType, '_', int2str(inputImgSize), '_' ];
%% train network
% a = find(imdb.images.set==1);
% imdb.images.set(a(300:end)) = 5;

[netbasemodel, info] = cnntrain_main004_withoutBN3(netbasemodel, imdb, prefixStr, fn, opts.train, 'conserveMemory', true);

%% leave blank for later use


